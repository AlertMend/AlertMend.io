import { BlogLayout } from "@/components/blog-layout";
import Thumbnail from "./thumbnail.jpeg";

export const blog = {
  author: { name: "Himanshu Bansal", src: "/img/avatar1.png" },
  date: "2025-06-8",
  title: "Elasticsearch Cluster Yellow Incident on Kubernetes: Troubleshooting and Solutions",
  description:
    "Elasticsearch requires adequate virtual memory to run smoothly. If the system‚Äôs virtual memory limit falls below the recommended level, Elasticsearch may encounter errors, impacting performance or causing downtime. A common error message, such as ‚Äúmax virtual memory areas vm.max_map_count [65530] is too low - This value is crucial as it determines the maximum number of memory-mapped areas that can be used. If set too low, users may experience issues like Elasticsearch failing to allocate enough memory for indexing operations,‚Äù signals that the system‚Äôs virtual memory needs adjustment. In this blog, we‚Äôll explore the causes, troubleshooting steps, and solutions for resolving Elasticsearch virtual memory limit issues.",
  image: "/img/blogs/Elasticsearch Cluster Yellow Incident on Kubernetes: Troubleshooting and Solutions.png",
};
export const metadata = {
  description: blog.description,
  keywords:
    'Elasticsearch yellow cluster status, Elasticsearch unassigned replica shards, Elasticsearch cluster troubleshooting, fix yellow cluster in Elasticsearch, Elasticsearch Kubernetes troubleshooting, Elasticsearch cluster health yellow, Elasticsearch shard allocation, Elasticsearch node failures, Elasticsearch resource constraints, Elasticsearch scaling Kubernetes, Elasticsearch disk space issues, resolve yellow cluster Elasticsearch, Elasticsearch best practices',
  openGraph: {
    images: [blog.image],
  },
  twitter: {
    card: 'summary_large_image',
    title: blog.title,
    description: blog.description,
    images: [blog.image],
  },
    alternates: {
    canonical: 'https://www.alertmend.io/blogs/Elasticsearch-Cluster-Yellow-Incident-on-Kubernetes.html',
  },
};

export default (props) => <BlogLayout blog={blog} {...props} />;


---
# üö® **Elasticsearch Cluster Yellow Incident on Kubernetes: Troubleshooting and Solutions**
---

An **Elasticsearch Cluster Yellow** incident indicates a partial degradation in the cluster's health, usually triggered by unassigned replica shards. This doesn‚Äôt affect the cluster‚Äôs immediate functionality but poses a risk of reduced redundancy, leading to potential data loss if a node fails. In this blog, we‚Äôll discuss the causes, debugging techniques, and steps to resolve a **yellow cluster status** in Kubernetes-managed Elasticsearch clusters.

---

## üîç **What Causes a Yellow Cluster Health Status in Elasticsearch?**

The **yellow status** typically occurs when **replica shards** are unassigned. Some of the common causes include:
- **Insufficient Nodes**: The number of nodes in the cluster might not be sufficient to allocate replica shards, as each node requires resources to handle primary and replica shards.
- **Node Failures**: When one or more nodes go down, replica shards can remain unassigned, which reduces data redundancy.
- **Resource Constraints**: Disk space or memory constraints on nodes can prevent replica shards from being allocated.
- **Network Issues**: Network connectivity problems between nodes can cause delays in replica shard assignment or hinder communication within the cluster.

---

## üõ†Ô∏è **Troubleshooting Elasticsearch Yellow Cluster Health**

### 1. **Check Elasticsearch Cluster Health**
Start by verifying the overall health of the Elasticsearch cluster:
```bash
kubectl exec -it ${ELASTICSEARCH_POD_NAME} -- curl -X GET 'http://localhost:9200/_cluster/health?pretty'
```
This command gives you the current cluster health status, highlighting unassigned shards or any issues. The `yellow` status specifically means that while all primary shards are assigned, one or more replica shards are unassigned.

### 2. **Inspect Cluster Status**
Get a detailed overview of the cluster's current status, including node states:
```bash
kubectl exec -it ${ELASTICSEARCH_POD_NAME} -- curl -X GET 'http://localhost:9200/_cat/health?v'
```

### 3. **List Elasticsearch Indices**
To investigate which indices may have unassigned shards, list all the indices and their health statuses:
```bash
kubectl exec -it ${ELASTICSEARCH_POD_NAME} -- curl -X GET 'http://localhost:9200/_cat/indices?v'
```

### 4. **Check Node Connectivity**
Ensure all nodes are up and communicating. Unassigned replica shards often result from disconnected nodes:
```bash
kubectl exec -it ${ELASTICSEARCH_POD_NAME} -- curl -X GET 'http://localhost:9200/_cat/nodes?v'
```
This command shows all nodes in the cluster and their status.

### 5. **Review Elasticsearch Logs**
Look for any errors or warnings that may indicate what is causing the yellow status:
```bash
kubectl logs ${ELASTICSEARCH_POD_NAME} ${ELASTICSEARCH_CONTAINER_NAME}
```
Logs can highlight resource-related issues like insufficient memory or disk, which might prevent proper shard assignment.

### 6. **Inspect Kubernetes Events**
Check Kubernetes events to see if there are any node failures, pod restarts, or resource-related issues impacting the Elasticsearch cluster:
```bash
kubectl get events --field-selector involvedObject.name=${ELASTICSEARCH_POD_NAME}
```

### 7. **Verify Disk Usage**
Disk space constraints can prevent shard allocation. Verify the disk usage on the nodes:
```bash
kubectl -n ${ELASTICSEARCH_NAMESPACE} exec -it ${ELASTICSEARCH_DEPLOYMENT_NAME} -- df -h
```

### 8. **Investigate Network Connectivity Issues**
Network connectivity issues can cause communication delays between nodes. Run the following script to check the status of your Elasticsearch pods and nodes:
```bash
#!/bin/bash

echo "Checking Elasticsearch pods and nodes status..."

kubectl get pods -l app=${YOUR_ELASTICSEARCH_LABEL}
kubectl exec ${ELASTICSEARCH_POD_NAME} -- curl -XGET 'http://localhost:9200/_cat/nodes'

# Check cluster health for yellow status
kubectl exec ${ELASTICSEARCH_POD_NAME} -- curl -XGET 'http://localhost:9200/_cluster/health' | grep yellow
```

---

## üõ°Ô∏è **Repairing Yellow Cluster Health**

### 1. **Scale Up the Elasticsearch Cluster**
To allocate unassigned replica shards, increase the number of nodes in the cluster. You can scale the deployment as follows:
```bash
kubectl scale deployment ${ELASTICSEARCH_DEPLOYMENT_NAME} --namespace ${ELASTICSEARCH_NAMESPACE} --replicas ${NEW_REPLICA_COUNT}
```
Adding more nodes will distribute the shards more effectively, improving redundancy and cluster health.

### 2. **Increase Resources on Nodes**
If the nodes are under resource pressure (e.g., low memory or disk), increase the resource allocation to resolve the issue:
```yaml
resources:
  requests:
    memory: "2Gi"
    cpu: "500m"
  limits:
    memory: "4Gi"
    cpu: "1000m"
```

### 3. **Allocate Unassigned Shards**
If the shards are still unassigned, you may need to trigger manual shard reallocation:
```bash
curl -X POST ${ELASTICSEARCH_URL}/_cluster/reroute?retry_failed
```
This will attempt to reassign unallocated shards and resolve the yellow status.

---

## üîÑ **Common Issues and Fixes for Elasticsearch Yellow Cluster Health**

| **Issue**                              | **Cause**                                      | **Solution**                                      |
|----------------------------------------|------------------------------------------------|---------------------------------------------------|
| Unassigned replica shards              | Insufficient nodes or resources                | Scale the cluster, add nodes, or free up resources |
| Node failures                          | Hardware or network issues                     | Restart failed nodes, resolve network issues       |
| Disk space exhaustion                  | Full disk on a node                            | Free up space or increase disk capacity            |
| Cluster health yellow after scaling    | Shards failed to reassign                      | Use `reroute` command to manually allocate shards  |

---

## üöÄ **Prevention and Best Practices**

### 1. **Monitor Disk Space and Resource Usage**
Set up proactive monitoring of disk space and other node resources. Tools like **Prometheus** and **Grafana** can be used to monitor key metrics such as memory, CPU, and disk usage, and trigger alerts when thresholds are crossed. Regular maintenance ensures node availability.

### 2. **Configure Replicas Properly**
Ensure each index has at least one replica for redundancy. Configure replica settings based on your environment's fault tolerance needs:
```yaml
index.number_of_replicas: 1
```

### 3. **Auto-Scaling Policies**
Use Kubernetes **Horizontal Pod Autoscaler (HPA)** to ensure that your Elasticsearch cluster can automatically scale based on CPU or memory usage, preventing resource exhaustion.

### 4. **Use Curator for Efficient Index Management**
To avoid overloading your cluster with too many shards, use **Elasticsearch Curator** to periodically delete older or less important indices, ensuring that your storage is used efficiently and that disk space remains available.

---

## üöÄ **Conclusion**

A **yellow cluster health status** in Elasticsearch indicates that some replica shards are unassigned, which can lead to decreased data redundancy and potential data loss if not resolved. By following the troubleshooting steps, scaling the cluster, and employing best practices, you can quickly restore your Elasticsearch cluster to a healthy state. Regular monitoring, proper resource allocation, and scaling policies are essential to maintaining high availability and preventing future yellow status incidents.